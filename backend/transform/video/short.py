# -*- coding: utf-8 -*-
"""
OMO Platform - ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ç”Ÿæˆ (å®Œå…¨ç‰ˆãƒ»å¼·åŒ–ç‰ˆ)

text_script ã®å°æœ¬ â†’ ãƒ“ãƒ¼ãƒˆã”ã¨ã«ç”»åƒç”Ÿæˆ â†’ å‹•ç”»
TTSå¤±æ•—æ™‚ã¯ç„¡éŸ³ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
"""

import sys
import os
import shutil
import hashlib
import tempfile
import subprocess
import re
from pathlib import Path
from typing import Dict, Any, Optional
from PIL import Image, ImageDraw, ImageFont

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

from backend.transform.core.base import BaseTransformer
from backend.common.storage import save_file
from backend.transform.video.tts import GeminiTTS
from backend.transform.video.image_gen import GeminiImageGenerator
from backend.transform.video.compositor import VideoCompositor


# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è§£åƒåº¦ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆè¨­å®šãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
DEFAULT_ASPECT_RATIO_SIZES = {
    "1:1": (1080, 1080),
    "9:16": (1080, 1920),
    "16:9": (1920, 1080),
}

# ã‚·ãƒ¼ãƒ³é•·ã®åˆ¶é™
MIN_SCENE_SEC = 3.0
MAX_SCENE_SEC = 20.0

# å‹•ç”»ã®æœ€å¾Œã®ä½™éŸ»(ç§’) - å„ã‚·ãƒ¼ãƒ³ã®æœ«å°¾ã¨BGMåˆæˆæ™‚ã®ä½™éŸ»
TAIL_SEC = 0.6


class VideoShortTransformer(BaseTransformer):
    """ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ç”Ÿæˆ"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.aspect_ratios = config.get("aspect_ratios", ["1:1"])
        self.fps = config.get("fps", 30)
        self.duration_max = config.get("duration_max", 60)
        self.generate_images = config.get("generate_images", False)  # ç”»åƒç”Ÿæˆãƒ•ãƒ©ã‚°
        
        # TTSè¨­å®š
        tts_config = config.get("tts", {})
        self.tts = GeminiTTS(
            model=tts_config.get("model", "gemini-2.5-flash-preview-tts"),
            voice=tts_config.get("voice", "Autonoe"),
            style=tts_config.get("style", "æ—¥æœ¬èªã§èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚"),
            pronunciation_dict=tts_config.get("pronunciation_dict", {})
        )
        
        # ç”»åƒç”Ÿæˆè¨­å®š
        self.image_gen = GeminiImageGenerator(
            model=config.get("image_model", "gemini-2.5-flash")
        )
        
        # ãƒ†ãƒ­ãƒƒãƒ—è¨­å®š
        self.telop_config = config.get("telop", {})
        
        # BGMè¨­å®š
        self.bgm_config = config.get("bgm", {})
        
        # å‚ç…§ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.reference_images_dir = config.get("reference_images_dir", "assets/video")
        self.image_size = config.get("image_size", "1K")
        
        # ä½™éŸ»è¨­å®š
        self.tail_sec = float(config.get("tail_sec", TAIL_SEC))
        
        # è§£åƒåº¦è¨­å®šã‚’èª­ã¿è¾¼ã¿
        resolution_config = config.get("resolution", {})
        self.aspect_ratio_sizes = {}
        for ratio, size in resolution_config.items():
            if isinstance(size, list) and len(size) == 2:
                self.aspect_ratio_sizes[ratio] = tuple(size)
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è¨­å®šãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨
        if not self.aspect_ratio_sizes:
            self.aspect_ratio_sizes = DEFAULT_ASPECT_RATIO_SIZES
        
        print(f"âœ¨ VideoShortTransformeråˆæœŸåŒ–: aspect_ratios={self.aspect_ratios}, resolutions={self.aspect_ratio_sizes}, tail_sec={self.tail_sec}")
        self.reference_images = {}

    def _load_reference_images(self) -> Dict[str, Image.Image]:
        """å‚ç…§ç”»åƒã‚’èª­ã¿è¾¼ã‚€"""
        images = {}
        if not self.reference_images_dir:
            return images
            
        ref_dir = Path(self.reference_images_dir)
        if not ref_dir.exists():
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã¨ã—ã¦è©¦ã™ (ç°¡æ˜“)
            # PYTHONPATHãŒé€šã£ã¦ã„ã‚‹å‰æã§ã€ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåŸºæº–ã§æ¢ã™
            pass

        if ref_dir.exists() and ref_dir.is_dir():
            for ext in ["*.png", "*.jpg", "*.jpeg", "*.webp"]:
                for img_path in ref_dir.glob(ext):
                    try:
                        img = Image.open(img_path)
                        images[img_path.name] = img
                        print(f"ğŸ–¼ï¸ å‚ç…§ç”»åƒãƒ­ãƒ¼ãƒ‰: {img_path.name}")
                    except Exception as e:
                        print(f"âš ï¸ å‚ç…§ç”»åƒãƒ­ãƒ¼ãƒ‰å¤±æ•— ({img_path.name}): {e}")
        return images
    
    def transform(self, article: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        è¨˜äº‹ã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆ
        """
        if not self.is_enabled():
            return None
        
        if not self.validate_article(article):
            print(f"âš ï¸ è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£: {article.get('title', 'unknown')}")
            return None
        
        try:
            # å‚ç…§ç”»åƒãƒ­ãƒ¼ãƒ‰
            self.reference_images = self._load_reference_images()
            
            # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            title = article.get("title", "")
            transformed_content = article.get("transformedContent", {})
            
            # å°æœ¬ã‚’å–å¾—
            script_data = transformed_content.get("text_script", {})
            
            if not script_data or not script_data.get("beats"):
                print(f"âš ï¸ å°æœ¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {title}")
                return None
            
            beats = script_data.get("beats", [])
            script_title = script_data.get("title", title)
            
            print(f"ğŸ¬ å‹•ç”»ç”Ÿæˆé–‹å§‹ (å°æœ¬ä½¿ç”¨): {title[:30]}... ({len(beats)}ã‚·ãƒ¼ãƒ³)")
            print(f"   ç”»åƒç”Ÿæˆ: {'ON' if self.generate_images else 'OFF (ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼)'} (model={self.image_gen.model})")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åç”¨ã®IDç”Ÿæˆ (ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹)
            # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ãˆãªã„æ–‡å­—ã‚’é™¤å»
            safe_title = re.sub(r'[\\/*?:"<>|]', "", script_title).replace(" ", "_")
            # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ã‚‹
            if len(safe_title) > 50:
                safe_title = safe_title[:50]
            
            file_base_name = safe_title
            
            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            with tempfile.TemporaryDirectory() as tmpdir:
                # å„ã‚·ãƒ¼ãƒ³ã®ç´ æã‚’ç”Ÿæˆ (éŸ³å£° + ç”»åƒ)
                scene_assets = []
                
                for i, beat in enumerate(beats, 1):
                    text = beat.get("text", "") or beat.get("narration", "")
                    image_prompt = beat.get("imagePrompt", "") or beat.get("visual_prompt", "")
                    
                    if not text:
                        continue
                    
                    # 1. éŸ³å£°ç”Ÿæˆ
                    audio_path = os.path.join(tmpdir, f"scene_{i}.mp3")
                    telop_text = beat.get("telop", "")
                    print(f"ğŸ”Š ã‚·ãƒ¼ãƒ³{i}/{len(beats)}")
                    print(f"   ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {text}")
                    print(f"   ãƒ†ãƒ­ãƒƒãƒ—: {telop_text}")
                    
                    success = False
                    try:
                        success = self.tts.generate(text, audio_path)
                    except Exception as e:
                        print(f"âš ï¸ TTSä¾‹å¤– (ã‚·ãƒ¼ãƒ³{i}): {e}")
                    
                    # å¤±æ•—ã¾ãŸã¯0ãƒã‚¤ãƒˆãªã‚‰ç„¡éŸ³ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    if not success or not os.path.exists(audio_path) or os.path.getsize(audio_path) == 0:
                        print(f"âš ï¸ TTSå¤±æ•— -> ç„¡éŸ³ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ (ã‚·ãƒ¼ãƒ³{i})")
                        duration = self._safe_len_seconds(text)
                        self._generate_silent_mp3(audio_path, duration)
                    else:
                        # ãƒ‡ãƒãƒƒã‚°: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª
                        try:
                            with open(audio_path, "rb") as f:
                                head = f.read(8)
                                hex_head = " ".join(f"{b:02X}" for b in head)
                                print(f"   [DEBUG] Audio File Header: {hex_head} (Size: {os.path.getsize(audio_path)})")
                        except Exception:
                            pass
                    
                    # æ¨å®šæ™‚é–“ã‚’è¨ˆç®— (ffprobeå¤±æ•—æ™‚ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç”¨)
                    estimated_duration = self._safe_len_seconds(text)
                    
                    scene_assets.append({
                        "scene_id": i,
                        "text": text,
                        "image_prompt": image_prompt,
                        "audio_path": audio_path,
                        "telop": beat.get("telop", text[:40]),
                        "estimated_duration": estimated_duration  # æ¨å®šæ™‚é–“ã‚’ä¿æŒ
                    })
                
                if not scene_assets:
                    print(f"âš ï¸ ã‚·ãƒ¼ãƒ³ç´ æç”Ÿæˆå¤±æ•—: {title}")
                    return None
                
                # å„ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã§å‹•ç”»ç”Ÿæˆ
                results = {}
                for aspect_ratio in self.aspect_ratios:
                    if aspect_ratio not in self.aspect_ratio_sizes:
                        print(f"âš ï¸ è§£åƒåº¦ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“: {aspect_ratio}")
                        continue
                    
                    # è§£åƒåº¦å–å¾—
                    width, height = self.aspect_ratio_sizes[aspect_ratio]
                    print(f"ğŸ¥ å‹•ç”»ç”Ÿæˆ ({aspect_ratio}, {width}x{height}): {title[:30]}...")
                    
                    # VideoCompositorä½œæˆ
                    compositor = VideoCompositor(width, height, self.fps, scene_padding=self.tail_sec)
                    
                    # å„ã‚·ãƒ¼ãƒ³ã®å‹•ç”»ã‚’ç”Ÿæˆ
                    scene_videos = []
                    for scene in scene_assets:
                        # ç”»åƒãƒ‘ã‚¹
                        image_path = os.path.join(tmpdir, f"scene_{scene['scene_id']}_{aspect_ratio.replace(':', 'x')}.png")
                        
                        # 2. ç”»åƒç”Ÿæˆ (ã¾ãŸã¯ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼)
                        if self.generate_images and scene["image_prompt"]:
                            # ç”»åƒç”Ÿæˆ
                            if not self.image_gen.generate(scene["image_prompt"], image_path, aspect_ratio, self.reference_images, self.image_size):
                                print(f"âš ï¸ ç”»åƒç”Ÿæˆå¤±æ•— -> ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ä½¿ç”¨")
                                self._create_placeholder(image_path, width, height, f"Scene {scene['scene_id']}")
                        else:
                            # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
                            self._create_placeholder(image_path, width, height, f"Scene {scene['scene_id']}")
                        
                        # 3. å‹•ç”»ã‚¯ãƒªãƒƒãƒ—ç”Ÿæˆ
                        scene_video_path = os.path.join(tmpdir, f"clip_{scene['scene_id']}_{aspect_ratio.replace(':', 'x')}.mp4")
                        
                        # æ¨å®šæ™‚é–“ã‚’æ¸¡ã™ (ffprobeãŒå¤±æ•—ã—ãŸå ´åˆã«ä½¿ç”¨ã•ã‚Œã‚‹)
                        success = compositor.create_video(
                            image_path=image_path,
                            audio_path=scene["audio_path"],
                            output_path=scene_video_path,
                            telop_text=scene["telop"] if self.telop_config.get("enabled") else None,
                            telop_config=self.telop_config if self.telop_config.get("enabled") else None,
                            duration=scene["estimated_duration"]  # ã“ã“ã§æ¸¡ã™
                        )
                        
                        if success:
                            scene_videos.append(scene_video_path)
                    
                    if not scene_videos:
                        print(f"âš ï¸ ã‚·ãƒ¼ãƒ³å‹•ç”»ç”Ÿæˆå¤±æ•— ({aspect_ratio}): {title}")
                        continue
                    
                    # ã‚·ãƒ¼ãƒ³ã‚’é€£çµ
                    temp_video_path = os.path.join(tmpdir, f"temp_{aspect_ratio.replace(':', 'x')}.mp4")
                    if len(scene_videos) == 1:
                        shutil.copy(scene_videos[0], temp_video_path)
                    else:
                        self._concat_videos(scene_videos, temp_video_path)
                    
                    # BGMåˆæˆ
                    final_video_path = os.path.join(tmpdir, f"final_{aspect_ratio.replace(':', 'x')}.mp4")
                    if self.bgm_config.get("enabled", False):
                        self._add_bgm(temp_video_path, final_video_path)
                    else:
                        shutil.move(temp_video_path, final_video_path)
                    
                    # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜
                    aspect_suffix = aspect_ratio.replace(':', 'x')
                    filename = f"videos/{file_base_name}_video_{aspect_suffix}.mp4"
                    storage_path = save_file(
                        open(final_video_path, "rb").read(),
                        filename,
                        "video/mp4"
                    )
                    
                    print(f"âœ… å‹•ç”»ç”ŸæˆæˆåŠŸ ({aspect_ratio}): {title[:30]}... -> {storage_path}")
                    
                    # çµæœã«è¿½åŠ 
                    key = f"video_path_{aspect_ratio.replace(':', '_')}"
                    results[key] = storage_path
            
            if not results:
                print(f"âŒ ã™ã¹ã¦ã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã§å‹•ç”»ç”Ÿæˆå¤±æ•—: {title}")
                return None
            
            return {
                **results,
                "script_title": script_title,
                "scene_count": len(beats),
                "aspect_ratios": self.aspect_ratios,
                "mime_type": "video/mp4"
            }
            
        except Exception as e:
            print(f"âŒ å‹•ç”»ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {article.get('title', 'unknown')} | {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _create_placeholder(self, path: str, width: int, height: int, text: str = ""):
        """ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒã‚’ç”Ÿæˆ"""
        img = Image.new("RGB", (width, height), "#f3f4f6")
        draw = ImageDraw.Draw(img)
        
        # ä¸­å¤®ã«å››è§’
        box_size = min(width, height) // 4
        left = (width - box_size) // 2
        top = (height - box_size) // 2
        draw.rectangle(
            [(left, top), (left + box_size, top + box_size)],
            outline="#d1d5db",
            width=6
        )
        
        # ãƒ†ã‚­ã‚¹ãƒˆæç”» (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        if text:
            try:
                font = ImageFont.load_default()
                draw.text((left, top - 20), text, fill="#000000", font=font)
            except:
                pass
        
        img.save(path, "PNG")
    
    def _concat_videos(self, video_paths: list, output_path: str):
        """è¤‡æ•°ã®å‹•ç”»ã‚’é€£çµ"""
        list_file = output_path + ".txt"
        with open(list_file, "w") as f:
            for video_path in video_paths:
                f.write(f"file '{video_path}'\n")
        
        cmd = [
            "ffmpeg", "-y",
            "-f", "concat",
            "-safe", "0",
            "-i", list_file,
            "-c", "copy",
            output_path
        ]
        
        subprocess.run(cmd, check=True, capture_output=True)
        os.remove(list_file)

    def _safe_len_seconds(self, text: str) -> float:
        """ãƒ†ã‚­ã‚¹ãƒˆé•·ã‹ã‚‰ç§’æ•°ã‚’æ¨å®š"""
        n = max(1, len(text or ""))
        sec = n / 6.0  # 1ç§’ã‚ãŸã‚Š6æ–‡å­—ã¨ä»®å®š
        return float(f"{max(MIN_SCENE_SEC, min(MAX_SCENE_SEC, sec)):.2f}")

    def _generate_silent_mp3(self, out_mp3: str, seconds: float) -> None:
        """ç„¡éŸ³MP3ã‚’ç”Ÿæˆ"""
        cmd = [
            "ffmpeg", "-y",
            "-f", "lavfi", "-i", "anullsrc=channel_layout=stereo:sample_rate=48000",
            "-t", f"{seconds:.2f}",
            "-c:a", "libmp3lame", "-b:a", "192k",
            "-ar", "48000", "-ac", "2",
            out_mp3,
        ]
        try:
            subprocess.run(cmd, check=True, capture_output=True)
            print(f"âœ… Silent narration saved: {out_mp3} ({seconds}s)")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Silent narration failed: {e}")

    def _add_bgm(self, video_path: str, output_path: str):
        """å‹•ç”»ã«BGMã‚’è¿½åŠ ï¼ˆãƒ«ãƒ¼ãƒ—å†ç”Ÿã€éŸ³é‡èª¿æ•´ã€ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆã€ä½™éŸ»ï¼‰"""
        bgm_path = self.bgm_config.get("file_path", "")
        volume = self.bgm_config.get("volume", 0.1)
        
        if not bgm_path or not os.path.exists(bgm_path):
            print(f"âš ï¸ BGMãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {bgm_path}")
            shutil.copy(video_path, output_path)
            return

        print(f"ğŸµ BGMåˆæˆ: {bgm_path} (Vol: {volume})")
        
        try:
            duration = self._get_video_duration(video_path)
            
            # å‹•ç”»ã¨éŸ³å£°ã«ä½™éŸ»ã‚’è¿½åŠ ã—ã€BGMã‚’ãƒŸãƒƒã‚¯ã‚¹
            # å‹•ç”»ã®é•·ã•ã‚’åŸºæº–ã«ã™ã‚‹(BGMãŒçŸ­ãã¦ã‚‚å‹•ç”»ã¯åˆ‡ã‚Œãªã„)
            fc = (
                f"[0:v]tpad=stop_mode=clone:stop_duration={self.tail_sec}[v1];"
                f"[0:a]asetpts=PTS-STARTPTS,apad=pad_dur={self.tail_sec},volume=1.0[a0];"
                f"[1:a]asetpts=PTS-STARTPTS,apad=pad_dur={self.tail_sec},volume={volume}[a1];"
                f"[a0][a1]amix=inputs=2:duration=longest:dropout_transition=2[aout]"
            )
            
            cmd = [
                "ffmpeg", "-y",
                "-i", video_path,
                "-stream_loop", "-1", "-i", bgm_path,
                "-filter_complex", fc,
                "-map", "[v1]", "-map", "[aout]",
                "-c:v", "libx264", "-profile:v", "high", "-level", "4.1",
                "-c:a", "aac", "-b:a", "192k",
                "-t", str(duration + self.tail_sec),  # å‹•ç”»ã®é•·ã•ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
                output_path
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
        except Exception as e:
            print(f"âš ï¸ BGMåˆæˆå¤±æ•—: {e}")
            shutil.copy(video_path, output_path)

    def _get_video_duration(self, path: str) -> float:
        """å‹•ç”»ã®é•·ã•ã‚’å–å¾—"""
        cmd = ["ffprobe", "-v", "error", "-show_entries", "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", path]
        result = subprocess.run(cmd, capture_output=True, text=True)
        try:
            return float(result.stdout.strip())
        except:
            return 0.0
